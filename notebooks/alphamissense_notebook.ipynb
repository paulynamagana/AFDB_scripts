{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/paulynamagana/afdb-analysis-tools/blob/main/notebooks/alphamissense_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using the Colab notebook\n",
        "\n",
        "Provide input: You'll need to provide:\n",
        "* A list of UniProt IDs.\n",
        "\n",
        "\n",
        "1. To run a code cell, click on the cell to select it. You will notice a play button (▶️) on the left side of the cell. Click on the play button or press Shift+Enter to run the code in the selected cell.\n",
        "2. The code will start executing, and you will see the output, if any, displayed below the code cell.\n",
        "3. Move to the next code cell and repeat steps 2 and 3 until you have executed all the desired code cells in sequence.\n",
        "4. The currently running step is indicated by a circle with a stop sign next to it. If you need to stop or interrupt the execution of a code cell, you can click on the stop button (■) located next to the play button.\n"
      ],
      "metadata": {
        "id": "XzvifV9fzV8E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-09-12T20:02:47.652806Z",
          "start_time": "2024-09-12T20:02:21.742612Z"
        },
        "id": "TAQHR-lH0eAz",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "import os\n",
        "import sys\n",
        "import requests\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "import seaborn as sns\n",
        "from matplotlib.colors import LinearSegmentedColormap\n",
        "from ipywidgets import interact, IntSlider, Button, HBox, VBox, Layout  # for save button\n",
        "\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "\n",
        "\n",
        "def fetch_AFDB_data(uniprot_accession):\n",
        "    \"\"\"Fetches data from the AlphaFold Database API.\n",
        "\n",
        "    Args:\n",
        "        uniprot_accession (str): The UniProt accession code.\n",
        "\n",
        "    Returns:\n",
        "        dict or None: The JSON result, or None on error.\n",
        "    \"\"\"\n",
        "    url = f\"https://alphafold.ebi.ac.uk/api/prediction/{uniprot_accession}\"\n",
        "    try:\n",
        "        logging.info(f\"Fetching data for {uniprot_accession}\")\n",
        "        response = requests.get(url, timeout=10)  # Added timeout\n",
        "        response.raise_for_status()\n",
        "        logging.info(f\"Successfully retrieved data for {uniprot_accession}\")\n",
        "        return response.json()\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        logging.error(f\"Error retrieving data for {uniprot_accession}: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def extract_alpha_missense_url(data):\n",
        "    \"\"\"Extracts the AlphaMissense URL from the API data.\n",
        "\n",
        "    Args:\n",
        "        data (dict): The JSON data from the API.\n",
        "\n",
        "    Returns:\n",
        "        str: The AlphaMissense URL, or an error message.\n",
        "    \"\"\"\n",
        "    if data and isinstance(data, list) and len(data) > 0:\n",
        "        logging.info(f\"Retrieving AlphaMissense data URL\")\n",
        "        return data[0].get('amAnnotationsUrl', \"No AlphaMissense data for this protein.\")\n",
        "    else:\n",
        "        return \"Error: No data provided or invalid format.\"\n",
        "\n",
        "\n",
        "def extract_pdb_url(data):\n",
        "    \"\"\"Extracts the PDB URL from the API data.\n",
        "\n",
        "    Args:\n",
        "        data (dict): The JSON data from the API.\n",
        "\n",
        "    Returns:\n",
        "        str: The PDB url, or an error message.\n",
        "    \"\"\"\n",
        "    if data and isinstance(data, list) and len(data) > 0:\n",
        "        logging.info(f\"Retrieving PDB file URL\")\n",
        "        return data[0].get('pdbUrl', \"Failed to retrieve PDB URL.\")\n",
        "    else:\n",
        "        return \"Error: No data provided or invalid format.\"\n",
        "\n",
        "\n",
        "def extract_am_data(am_url):\n",
        "    \"\"\"Extracts AlphaMissense data from the URL and saves it as a CSV file.\n",
        "\n",
        "    Args:\n",
        "        am_url (str): URL to the AlphaMissense data CSV.\n",
        "\n",
        "    Returns:\n",
        "        pandas.DataFrame or None: The AlphaMissense data, or None on error.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        logging.info(f\"Reading AlphaMissense data from {am_url}\")\n",
        "        am_file = pd.read_csv(am_url)\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error reading AlphaMissense file: {e}\")\n",
        "        return None\n",
        "\n",
        "    reference_aa = am_file[\"protein_variant\"].str.extract(r'^([A-Z])')[0]\n",
        "    alternative_aa = am_file[\"protein_variant\"].str.extract('([A-Z])$')[0]\n",
        "    residue_number = pd.to_numeric(am_file[\"protein_variant\"].str.extract(r'([0-9]+)')[0])\n",
        "    pathogenicity_score = pd.to_numeric(am_file['am_pathogenicity'])\n",
        "\n",
        "    am_data = pd.DataFrame({\n",
        "        'reference_aa': reference_aa,\n",
        "        'residue_number': residue_number,\n",
        "        \"alternative_aa\": alternative_aa,\n",
        "        \"pathogenicity_score\": pathogenicity_score\n",
        "    })\n",
        "\n",
        "    output_directory = \"data_output\"\n",
        "    ensure_directory_exists(output_directory)\n",
        "    output_filename = os.path.basename(am_url)\n",
        "    output_file = os.path.join(output_directory, output_filename)\n",
        "\n",
        "    try:\n",
        "        am_data.to_csv(output_file, index=False)\n",
        "        logging.info(f\"AlphaMissense data saved to: {output_filename}\")\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error saving AlphaMissense data: {e}\")\n",
        "\n",
        "    return am_data\n",
        "\n",
        "\n",
        "def calculate_average_pathogenicity(am_data):\n",
        "    \"\"\"Calculates average pathogenicity scores per residue from AlphaMissense data.\n",
        "\n",
        "    Args:\n",
        "        am_data (pandas.DataFrame): DataFrame containing AlphaMissense data.\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray or None: Array of average pathogenicity scores, or None on error.\n",
        "    \"\"\"\n",
        "    if am_data is None:\n",
        "        logging.error(\"No AlphaMissense data available, check if UniProt has AlphaMissense data.\")\n",
        "        return None\n",
        "\n",
        "    grouped = am_data.groupby(['residue_number'])['pathogenicity_score'].mean().reset_index()\n",
        "    max_residue_number = grouped['residue_number'].max()\n",
        "    average_scores = np.full(max_residue_number + 1, np.nan)\n",
        "\n",
        "    for _, row in grouped.iterrows():\n",
        "        residue_number = int(row['residue_number'])\n",
        "        average_scores[residue_number] = round(row['pathogenicity_score'], 4)\n",
        "    return average_scores\n",
        "\n",
        "\n",
        "def modify_pdb_with_am_data(pdb_url, average_scores_file):\n",
        "    \"\"\"Modifies a PDB file with AlphaMissense pathogenicity scores.\n",
        "\n",
        "    Args:\n",
        "        pdb_url (str): URL to the PDB file.\n",
        "        average_scores_file (numpy.ndarray): Array of average pathogenicity scores.\n",
        "    \"\"\"\n",
        "    if not pdb_url:\n",
        "        logging.error(\"PDB URL is not provided.\")\n",
        "        return\n",
        "\n",
        "    try:\n",
        "        logging.info(\"Retrieving PDB file\")\n",
        "        response = requests.get(pdb_url, timeout=10)\n",
        "        response.raise_for_status()\n",
        "        pdb_content = response.text.splitlines()\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        logging.error(f\"Failed to retrieve the PDB file: {e}\")\n",
        "        return\n",
        "\n",
        "    output_directory = \"data_output\"\n",
        "    ensure_directory_exists(output_directory)\n",
        "\n",
        "    base_filename = os.path.basename(pdb_url)\n",
        "    output_filename = f\"AM_scores_{base_filename}\"\n",
        "    output_file = os.path.join(output_directory, output_filename)\n",
        "\n",
        "    try:\n",
        "        logging.info(f\"Writing modified PDB data to: {output_file}\")\n",
        "        with open(output_file, \"w\", encoding=\"utf-8\") as out_file:\n",
        "            for line in pdb_content:\n",
        "                if line.startswith(\"ATOM\") or line.startswith(\"HETATM\"):\n",
        "                    residue_number = int(line[22:26].strip())\n",
        "                    if residue_number < len(average_scores_file) and not np.isnan(average_scores_file[residue_number]):\n",
        "                        value = average_scores_file[residue_number]\n",
        "                        value_str = f\"{value:.2f}\"\n",
        "                        while len(value_str) < 6:\n",
        "                            value_str = \" \" + value_str\n",
        "                        edit_line = line[:60] + value_str + line[66:]\n",
        "                        out_file.write(edit_line + '\\n')\n",
        "                    else:\n",
        "                        out_file.write(line + '\\n')\n",
        "                else:\n",
        "                    out_file.write(line + '\\n')\n",
        "    except IOError as e:\n",
        "        logging.error(f\"Error writing to file: {e}\")\n",
        "\n",
        "\n",
        "def extract_pathogenicity_and_plddt(am_file_path, pdb_file_url):\n",
        "    \"\"\"Extracts pathogenicity and pLDDT scores from AM and PDB files.\n",
        "\n",
        "    Args:\n",
        "        am_file_path (str): Path to the AM file.\n",
        "        pdb_file_url (str): URL to the PDB file.\n",
        "\n",
        "    Returns:\n",
        "        tuple: Lists of pathogenicity and pLDDT scores.\n",
        "    \"\"\"\n",
        "    pathogenicity_scores = {}\n",
        "    plddt_scores = {}\n",
        "\n",
        "    try:\n",
        "        with open(am_file_path, \"r\") as f:\n",
        "            am_pdb = f.read()\n",
        "\n",
        "        for line in am_pdb.splitlines():\n",
        "            if line.startswith((\"ATOM\", \"HETATM\")):\n",
        "                residue_number = int(line[22:26].strip())\n",
        "                score = float(line[60:66].strip())\n",
        "                pathogenicity_scores.setdefault(residue_number, []).append(score)\n",
        "\n",
        "        pathogenicity_scores = {\n",
        "            residue: sum(scores) / len(scores) for residue, scores in pathogenicity_scores.items()\n",
        "        }\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        logging.error(f\"AM file not found: {am_file_path}\")\n",
        "    except ValueError:\n",
        "        logging.error(\"Error parsing pathogenicity scores in AM file.\")\n",
        "\n",
        "    if pdb_file_url:\n",
        "        try:\n",
        "            response = requests.get(pdb_file_url, timeout=10)\n",
        "            response.raise_for_status()\n",
        "            pdb_content = response.text.splitlines()\n",
        "\n",
        "            for line in pdb_content:\n",
        "                if line.startswith((\"ATOM\", \"HETATM\")):\n",
        "                    residue_number = int(line[22:26].strip())\n",
        "                    score = float(line[60:66].strip())\n",
        "                    plddt_scores.setdefault(residue_number, []).append(score)\n",
        "\n",
        "            plddt_scores = {\n",
        "                residue: sum(scores) / len(scores) for residue, scores in plddt_scores.items()\n",
        "            }\n",
        "\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            logging.error(f\"Error fetching PDB data: {e}\")\n",
        "        except ValueError:\n",
        "            logging.error(\"Error parsing pLDDT scores in PDB file.\")\n",
        "\n",
        "    residues = sorted(set(pathogenicity_scores.keys()).union(set(plddt_scores.keys())))\n",
        "    pathogenicity_scores_list = [pathogenicity_scores.get(residue, None) for residue in residues]\n",
        "    plddt_scores_list = [plddt_scores.get(residue, None) for residue in residues]\n",
        "\n",
        "    return pathogenicity_scores_list, plddt_scores_list\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def plot_scores(pathogenicity_scores, plddt_scores, uniprot_id):\n",
        "    \"\"\"\n",
        "    Plots pathogenicity and rescaled pLDDT scores against residue number using Seaborn.\n",
        "\n",
        "    Args:\n",
        "        pathogenicity_scores (list): List of pathogenicity scores.\n",
        "        plddt_scores (list): List of pLDDT scores.\n",
        "    \"\"\"\n",
        "\n",
        "    # Rescale pLDDT scores from 0-100 to 0-1\n",
        "    plddt_rescaled = [score / 100 for score in plddt_scores]\n",
        "\n",
        "    # Create a DataFrame for easy plotting with Seaborn\n",
        "    data = {\n",
        "        'Residue number': range(1, len(pathogenicity_scores) + 1),\n",
        "        'Average pathogenicity': pathogenicity_scores,\n",
        "        'pLDDT (rescaled)': plddt_rescaled\n",
        "    }\n",
        "    df = pd.DataFrame(data)\n",
        "\n",
        "    # Create line plots with Seaborn\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    ax = plt.subplot(111)\n",
        "    sns.lineplot(x='Residue number', y='Average pathogenicity', data=df, label='Average AM score')\n",
        "    sns.lineplot(x='Residue number', y='pLDDT (rescaled)', data=df, label='pLDDT (rescaled)')\n",
        "\n",
        "    # Add labels, title, and legend\n",
        "    plt.xlabel('Residue number')\n",
        "    plt.ylabel('Score')\n",
        "    plt.title(f'Average AM and pLDDT scores per position ({uniprot_id})')\n",
        "    plt.legend()\n",
        "    plt.xlim(1, len(pathogenicity_scores))\n",
        "\n",
        "    if len(pathogenicity_scores) > 200:\n",
        "        ax.xaxis.set_major_locator(ticker.MultipleLocator(100))  # Set marks every 100 residues\n",
        "    else:\n",
        "        ax.xaxis.set_major_locator(ticker.MultipleLocator(50))  # Set marks every 100 residues\n",
        "\n",
        "    ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.1),\n",
        "                fancybox=True, shadow=True, ncol=5)\n",
        "\n",
        "    plt.grid(axis='y', linestyle='--')  # Optional grid\n",
        "\n",
        "        # Save the plot to a file\n",
        "    plt.tight_layout(rect=[0, 0.1, 1, 1])  # Leaves space below for the legend\n",
        "\n",
        "        # Save the plot to a file\n",
        "    output_directory = \"data_output\"\n",
        "    output_file = os.path.join(output_directory, f\"graph_plDDT-AM-score_{uniprot_id}.png\")\n",
        "    plt.savefig(output_file) #save file\n",
        "\n",
        "    # Show the plot\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "def plot_am_heatmap(am_data, uniprot_id):\n",
        "    \"\"\"\n",
        "    Plots a heatmap for the AlphaMissense data with reference residues on x and alternative_aa on y axis\n",
        "    Colour coded following the original colours from the AlphaFold Database, see: https://alphafold.ebi.ac.uk/entry/Q5VSL9\n",
        "    \"\"\"\n",
        "\n",
        "    #custom palette\n",
        "    def create_custom_colormap():\n",
        "        cdict = {\n",
        "            'red': [\n",
        "                (0.0, 56/255, 56/255),\n",
        "                (0.34, 204/255, 204/255),\n",
        "                (0.464, 204/255, 204/255),\n",
        "                (1.0, 165/255, 165/255)\n",
        "            ],\n",
        "            'green': [\n",
        "                (0.0, 83/255, 83/255),\n",
        "                (0.34, 204/255, 204/255),\n",
        "                (0.464, 204/255, 204/255),\n",
        "                (1.0, 13/255, 13/255)\n",
        "            ],\n",
        "            'blue': [\n",
        "                (0.0, 163/255, 163/255),\n",
        "                (0.34, 204/255, 204/255),\n",
        "                (0.464, 204/255, 204/255),\n",
        "                (1.0, 18/255, 18/255)\n",
        "            ]\n",
        "        }\n",
        "        return LinearSegmentedColormap('CustomMap', segmentdata=cdict)\n",
        "\n",
        "    # custom colormap\n",
        "    custom_cmap = create_custom_colormap()\n",
        "\n",
        "    # pivot table\n",
        "    pivot_table = am_data.pivot_table(values='pathogenicity_score', index='alternative_aa', columns='reference_aa', aggfunc='mean')\n",
        "    pivot_table = pd.pivot_table(am_data, values='pathogenicity_score',\n",
        "    index='alternative_aa', columns='residue_number')\n",
        "\n",
        "    #custom_order = [\"R\", \"H\", \"K\", \"D\", \"E\", \"S\", \"T\", \"N\", \"Q\", \"C\", \"P\", \"A\", \"V\", \"I\", \"L\", \"M\", \"G\", \"F\",\"Y\",\"W\"]\n",
        "\n",
        "    # Reindex the pivot table\n",
        "    #pivot_table = pivot_table.reindex(custom_order)\n",
        "\n",
        "    plt.figure(figsize=(14, 6))\n",
        "\n",
        "    ax = sns.heatmap(pivot_table, cmap=custom_cmap, vmin=0, vmax=1,\n",
        "    cbar_kws={'label': 'AlphaMissense score'}) # Limits for the color scale\n",
        "\n",
        "    ax.set_xlabel('Residue Number')\n",
        "    ax.set_ylabel('Alternative Amino Acid')\n",
        "    plt.title(f'AlphaMissense Pathogenicity Heatmap ({uniprot_id})')\n",
        "\n",
        "    xticks = range(0, pivot_table.shape[1], 50)\n",
        "    ax.set_xticks(xticks)\n",
        "    ax.set_xticklabels(pivot_table.columns[xticks])\n",
        "    ax.set_facecolor('black') #Set background black for matching AA\n",
        "    plt.yticks(rotation = 0)\n",
        "\n",
        "    cbar = ax.collections[0].colorbar\n",
        "    cbar.set_ticks([i / 10.0 for i in range(11)])\n",
        "    cbar.set_ticklabels([f'{i / 10.0:.1f}' for i in range(11)])\n",
        "    plt.tight_layout()\n",
        "\n",
        "\n",
        "    # Save the plot to a file\n",
        "    output_directory = \"data_output\"\n",
        "    ensure_directory_exists(output_directory)\n",
        "\n",
        "    output_file = os.path.join(output_directory, f\"AM_heatmap_{uniprot_id}.png\")\n",
        "    plt.savefig(output_file) #save file\n",
        "    plt.show() # Show plot\n",
        "\n",
        "    plt.close() # Close the figure after saving to free up resources\n",
        "\n",
        "def ensure_directory_exists(directory):\n",
        "    if not os.path.exists(directory):\n",
        "        os.makedirs(directory)\n",
        "        logging.info(f\"Created directory: {directory}\")\n",
        "\n",
        "\n",
        "\n",
        "#@title <font color='#e59454'>Retrieve data from AlphaFold Database\n",
        "sys.path.insert(1, '/content/AFDB_scripts')\n",
        "\n",
        "uniprot_id =  \"Q9Y5P2\" #@param {type:\"string\"}\n",
        "\n",
        "# Step 1: Split the input string by commas and strip whitespace\n",
        "uniprot_ids = [accession.strip() for accession in uniprot_id.split(',')]\n",
        "\n",
        "output_directory = \"data_output\"\n",
        "ensure_directory_exists(output_directory)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "TgNcuDBHw_Bs",
        "outputId": "b687be55-a908-49e4-a0aa-c91af32ef07e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:root:Error retrieving data for Q9Y5P2: HTTPSConnectionPool(host='alphafold.ebi.ac.uk', port=443): Read timed out. (read timeout=10)\n"
          ]
        }
      ],
      "source": [
        "#@title <font color='#e59454'>Show plddt vs average AlphaMissense plots & AlphaMissense heatmap\n",
        "\n",
        "for uniprot_id in uniprot_ids:\n",
        "  alphafold_data = fetch_AFDB_data(uniprot_id)\n",
        "  if alphafold_data:\n",
        "    am_data=extract_am_data(am_url=extract_alpha_missense_url(alphafold_data))\n",
        "    pdb_data_url = extract_pdb_url(alphafold_data)\n",
        "    modify_pdb_with_am_data(pdb_data_url, average_scores_file=calculate_average_pathogenicity(am_data))\n",
        "    file_path= f\"data_output/AM_scores_AF-{uniprot_id}-F1-model_v4.pdb\"\n",
        "    pathogenicity_scores, plddt_scores = extract_pathogenicity_and_plddt(file_path, pdb_data_url)\n",
        "\n",
        "    print(f\"Sucessfully retrieved data for {uniprot_id}\")\n",
        "    plot_scores(pathogenicity_scores, plddt_scores, uniprot_id)\n",
        "    plot_am_heatmap(am_data, uniprot_id)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title <font color='#e59454'>Show zoomed heatmap\n",
        "#@markdown In this part of the Google Colab, you will be able to choose the UniProt ID, make sure you have run the previous code blocks to retrieve the data.\n",
        "\n",
        "\n",
        "def ensure_directory_exists(directory):\n",
        "    \"\"\"Ensures that the specified directory exists.\n",
        "\n",
        "    Args:\n",
        "        directory (str): The path to the directory.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(directory):\n",
        "        os.makedirs(directory)\n",
        "        logging.info(f\"Created directory: {directory}\")\n",
        "\n",
        "\n",
        "def save_am_data(am_data, uniprot_id, output_directory):\n",
        "    \"\"\"Saves AlphaMissense data to a CSV file.\n",
        "\n",
        "    Args:\n",
        "        am_data (pandas.DataFrame): The AlphaMissense data.\n",
        "        uniprot_id (str): The UniProt ID.\n",
        "        output_directory (str): The directory to save the file.\n",
        "    \"\"\"\n",
        "    output_file = os.path.join(output_directory, f\"AM_data_{uniprot_id}.csv\")\n",
        "    am_data.to_csv(output_file, index=False)\n",
        "    logging.info(f\"Saved AM data for {uniprot_id} to {output_file}\")\n",
        "\n",
        "\n",
        "def load_am_data(uniprot_id, output_directory):\n",
        "    \"\"\"Loads AlphaMissense data from a CSV file.\n",
        "\n",
        "    Args:\n",
        "        uniprot_id (str): The UniProt ID.\n",
        "        output_directory (str): The directory where the file is located.\n",
        "\n",
        "    Returns:\n",
        "        pandas.DataFrame or None: The AlphaMissense data, or None if the file does not exist.\n",
        "    \"\"\"\n",
        "    input_file = os.path.join(output_directory, f\"AM_data_{uniprot_id}.csv\")\n",
        "    if os.path.exists(input_file):\n",
        "        am_data = pd.read_csv(input_file)\n",
        "        logging.info(f\"Loaded AM data for {uniprot_id} from {input_file}\")\n",
        "        return am_data\n",
        "    else:\n",
        "        logging.error(f\"No AM data found for {uniprot_id} in {output_directory}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def plot_am_heatmap_zoom(am_data, uniprot_id, number_minimum, number_maximum, output_directory, save_plot=False, show_plot=True):\n",
        "    \"\"\"Plots and optionally saves a zoomed heatmap of AlphaMissense data.\n",
        "\n",
        "    Args:\n",
        "        am_data (pandas.DataFrame): The AlphaMissense data.\n",
        "        uniprot_id (str): The UniProt ID.\n",
        "        number_minimum (int): The minimum residue number for the zoom.\n",
        "        number_maximum (int): The maximum residue number for the zoom.\n",
        "        output_directory (str): The directory to save the plot.\n",
        "        save_plot (bool): If True, saves the plot to a file.\n",
        "        show_plot (bool): If True shows the plot.\n",
        "    \"\"\"\n",
        "    def create_custom_colormap():\n",
        "        cdict = {\n",
        "            'red': [(0.0, 56/255, 56/255), (0.34, 204/255, 204/255), (0.464, 204/255, 204/255), (1.0, 165/255, 165/255)],\n",
        "            'green': [(0.0, 83/255, 83/255), (0.34, 204/255, 204/255), (0.464, 204/255, 204/255), (1.0, 13/255, 13/255)],\n",
        "            'blue': [(0.0, 163/255, 163/255), (0.34, 204/255, 204/255), (0.464, 204/255, 204/255), (1.0, 18/255, 18/255)]\n",
        "        }\n",
        "        return LinearSegmentedColormap('CustomMap', segmentdata=cdict)\n",
        "\n",
        "    custom_cmap = create_custom_colormap()\n",
        "    filtered_data = am_data[(am_data['residue_number'] >= number_minimum) & (am_data['residue_number'] <= number_maximum)]\n",
        "    pivot_table = pd.pivot_table(filtered_data, values='pathogenicity_score', index='alternative_aa', columns='residue_number')\n",
        "\n",
        "    plt.figure(figsize=(20, 6))\n",
        "    ax = sns.heatmap(pivot_table, cmap=custom_cmap, vmin=0, vmax=1, cbar_kws={'label': 'AlphaMissense score'})\n",
        "    ax.set_xlabel('Residue Number')\n",
        "    ax.set_ylabel('Alternative Amino Acid')\n",
        "    plt.title(f'AlphaMissense Pathogenicity Heatmap ({uniprot_id}) - Residues {number_minimum} to {number_maximum}')\n",
        "    ax.set_xticks(range(0, pivot_table.shape[1]))\n",
        "    ax.set_xticklabels(pivot_table.columns, rotation=90)\n",
        "    ax.set_facecolor('black')\n",
        "    plt.yticks(rotation=0)\n",
        "\n",
        "    cbar = ax.collections[0].colorbar\n",
        "    cbar.set_ticks([i / 10.0 for i in range(11)])\n",
        "    cbar.set_ticklabels([f'{i / 10.0:.1f}' for i in range(11)])\n",
        "    plt.tight_layout()\n",
        "\n",
        "    if save_plot:\n",
        "        output_file = os.path.join(output_directory, f\"AM_heatmap_zoom_{uniprot_id}_{number_minimum}_{number_maximum}.png\")\n",
        "        plt.savefig(output_file)\n",
        "        logging.info(f\"Saved zoomed heatmap to {output_file}\")\n",
        "\n",
        "    if show_plot:\n",
        "        plt.show()\n",
        "        plt.close()\n",
        "    else:\n",
        "        plt.close()\n",
        "\n",
        "\n",
        "def main_workflow(uniprot_ids, output_directory):\n",
        "    \"\"\"Main workflow to process and visualize AlphaMissense data.\n",
        "\n",
        "    Args:\n",
        "        uniprot_ids (list): A list of UniProt IDs.\n",
        "        output_directory (str): The directory to save output files.\n",
        "    \"\"\"\n",
        "    ensure_directory_exists(output_directory)\n",
        "\n",
        "    for uniprot_id in uniprot_ids:\n",
        "        am_data = load_am_data(uniprot_id, output_directory)\n",
        "\n",
        "        if am_data is not None:\n",
        "            minimum_slider = IntSlider(min=1, max=am_data['residue_number'].max(), step=1, value=1, description='Min Residue:')\n",
        "            maximum_slider = IntSlider(min=1, max=am_data['residue_number'].max(), step=1, value=min(100, am_data['residue_number'].max()), description='Max Residue:')\n",
        "            save_button = Button(description=\"SAVE PLOT\", layout=Layout(width='30%', height='80px'))\n",
        "\n",
        "            def on_save_button_click(b):\n",
        "                plot_am_heatmap_zoom(am_data, uniprot_id, minimum_slider.value, maximum_slider.value, output_directory, save_plot=True, show_plot=False)\n",
        "\n",
        "            save_button.on_click(on_save_button_click)\n",
        "\n",
        "            def update_plot(minimum, maximum):\n",
        "                plot_am_heatmap_zoom(am_data, uniprot_id, minimum, maximum, output_directory, save_plot=False)\n",
        "\n",
        "            interact(update_plot, minimum=minimum_slider, maximum=maximum_slider)\n",
        "            display(save_button)\n",
        "\n",
        "\n",
        "# Example usage\n",
        "uniprot_id = \"Q9Y5P2\"  # @param {type:\"string\"}\n",
        "uniprot_ids = [accession.strip() for accession in uniprot_id.split(',')]\n",
        "output_directory = \"data_output\"\n",
        "\n",
        "main_workflow(uniprot_ids, output_directory)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "N0fcR5Wm0EOs",
        "outputId": "0dcd787f-2496-402a-a815-d384278be721",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:root:No AM data found for Q9Y5P2 in data_output\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "HC21GJD40u7V",
        "cellView": "form",
        "outputId": "729f4cf7-c480-4e6a-f0b7-18b8a7623a4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'Path' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-c57d68b3e23d>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;31m# Example usage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0mzip_and_download_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-4-c57d68b3e23d>\u001b[0m in \u001b[0;36mzip_and_download_files\u001b[0;34m(folder_path, zip_filename)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mzip_filename\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mName\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mzip\u001b[0m \u001b[0marchive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \"\"\"\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mfolder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Path' is not defined"
          ]
        }
      ],
      "source": [
        "#@title <font color='#e59454'>Downloading Results\n",
        "\n",
        "#@markdown This cell creates a zip file containing all the previouosly generated plots and modified PDB files, allowing you to easily download and save your results. Here's what's happening:\n",
        "\n",
        "#@markdown  * **Gathering Files**: The code collects all the generated plot images (in PNG format) and the modified PDB files where the B-factor column now holds the AlphaMissense scores.\n",
        "\n",
        "#@markdown  * **Creating a Zip Archive**:  A zip file named results.zip is created within the Colab environment.\n",
        "\n",
        "#@markdown  * **Adding** **Files**: All the collected plot images and modified PDB files are added to this results.zip archive.\n",
        "\n",
        "#@markdown  * **Downloading** **the** **Zip** **File**: This cell will initiate a download of this results.zip file to your local machine. You'll typically see a download prompt in your browser.\n",
        "\n",
        "import zipfile\n",
        "from pathlib import Path\n",
        "\n",
        "def zip_and_download_files(folder_path=\"./data_output/\", zip_filename=\"AM_files.zip\"):\n",
        "    \"\"\"Zips files in a folder and downloads the zip archive.\n",
        "\n",
        "    Args:\n",
        "        folder_path (str): Path to the folder containing files to zip.\n",
        "        zip_filename (str): Name of the zip archive.\n",
        "    \"\"\"\n",
        "    folder = Path(folder_path)\n",
        "\n",
        "    try:\n",
        "        with zipfile.ZipFile(zip_filename, 'w') as zipf:\n",
        "            for file in folder.iterdir():\n",
        "                if file.is_file():\n",
        "                    zipf.write(file, arcname=file.name)\n",
        "                    os.remove(file)\n",
        "        logging.info(f\"Created zip archive: {zip_filename}\")\n",
        "        files.download(zip_filename)\n",
        "        logging.info(f\"Downloaded zip archive: {zip_filename}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error during zipping and download: {e}\")\n",
        "\n",
        "# Example usage\n",
        "zip_and_download_files()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}